# ==============================================================================
# SuperAI - AGI Research Environment Orchestration
# Version: 2.0 (Phoenix Architecture)
#
# This Docker Compose file is configured to use environment variables from
# .env (for non-sensitive data) and docker-secrets.env (for sensitive data).
# ==============================================================================
services:
  vllm-service:
    build:
      context: ./microservices/vllm-service
      dockerfile: Dockerfile
    container_name: vllm-service
    ports:
      - "8000:8000"
    volumes:
      - vllm-models:/root/.cache/vllm
      - ./models/Qwen1.5-1.8B-Chat:/models/Qwen1.5-1.8B-Chat
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: --model /models/Qwen1.5-1.8B-Chat --host 0.0.0.0
    networks:
      - agi-internal

  agi-qwen-service:
    build:
      context: .
      dockerfile: ./microservices/agi-qwen-service/Dockerfile.agi
    container_name: agi-qwen-service
    ports:
      - "8201:8200"
    env_file:
      - .env
    environment:
      - SERVICE_NAME=agi-qwen-service
      - SERVICE_PORT=8200
      - VLLM_API_URL=http://vllm-service:8000/v1/chat/completions
      - VLLM_MODEL=Qwen/Qwen1.5-1.8B-Chat
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8200/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - vllm-service
    volumes:
      - ./scripts:/app/scripts
    networks:
      - agi-internal

  agi-qwen-lb:
    build:
      context: ./microservices/agi-qwen-lb
      dockerfile: Dockerfile
    container_name: agi-qwen-lb
    ports:
      - "8202:80"
    depends_on:
      - agi-qwen-service
    networks:
      - agi-public
      - agi-internal

  agi-synergy-api-lb:
    build:
      context: ./microservices/agi-synergy-api-lb
      dockerfile: Dockerfile
    container_name: agi-synergy-api-lb
    ports:
      - "8199:80"
    depends_on:
      - agent-executor
    environment:
      - SERVICE_NAME=synergy-api-lb
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - agi-public
      - agi-internal

  agi-learning-api-lb:
    build:
      context: ./microservices/agi-learning-api-lb
      dockerfile: Dockerfile
    container_name: agi-learning-api-lb
    ports:
      - "8200:80"
    environment:
      - SERVICE_NAME=learning-api-lb
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - agi-public
      - agi-internal

  health-check-proxy:
    build:
      context: ./microservices/health-check-proxy
      dockerfile: Dockerfile
    container_name: health-check-proxy
    ports:
      - "8105:80"
    environment:
      - SERVICE_NAME=health-check-proxy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - agi-public
      - agi-internal

  agi-prometheus:
    image: prom/prometheus:latest
    container_name: agi-prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/prometheus
    networks:
      - agi-internal

  agi-grafana:
    image: grafana/grafana:latest
    container_name: agi-grafana
    ports:
      - "3000:3000"
    env_file:
      - docker-secrets.env
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - agi-prometheus
    networks:
      - agi-internal

  agi-redis-lb:
    image: redis:7-alpine
    container_name: agi-redis-lb
    ports:
      - "6379:6379"
    env_file:
      - .env
      - docker-secrets.env
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    networks:
      - agi-internal

  agi-evolution-manager:
    build:
      context: .
      dockerfile: ./microservices/agi-evolution-manager/Dockerfile.agi
    container_name: agi-evolution-manager
    env_file:
      - .env
    environment:
      - SERVICE_NAME=evolution-manager
    networks:
      - agi-internal

  agi-v4-enhanced:
    build:
      context: ./microservices/agi-v4-enhanced
      dockerfile: Dockerfile.agi
    container_name: agi-v4-enhanced
    env_file:
      - .env
    environment:
      - SERVICE_NAME=v4-enhanced
    networks:
      - agi-internal

  agi-test-validation:
    build:
      context: ./microservices/agi-test-validation
      dockerfile: Dockerfile
    container_name: agi-test-validation
    env_file:
      - .env
    environment:
      - SERVICE_NAME=test-validation
    networks:
      - agi-internal

  agi-comprehensive-monitoring-enhanced:
    build:
      context: ./microservices/agi-comprehensive-monitoring-enhanced
      dockerfile: Dockerfile
    container_name: agi-comprehensive-monitoring-enhanced
    env_file:
      - .env
    environment:
      - SERVICE_NAME=comprehensive-monitoring
    networks:
      - agi-internal

  agent-planner:
    build:
      context: .
      dockerfile: ./microservices/agent-planner/Dockerfile.agi
    container_name: agent-planner
    working_dir: /app/microservices/agent-planner
    ports:
      - "8300:8300"
    env_file:
      - .env
      - docker-secrets.env
    environment:
      - SERVICE_NAME=agent-planner
      - SERVICE_PORT=8300
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8300/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - ./scripts:/app/scripts
    networks:
      - agi-internal

  agent-executor:
    build:
      context: .
      dockerfile: ./microservices/agent-executor/Dockerfile.agi
    container_name: agent-executor
    ports:
      - "8400:8400"
    env_file:
      - .env
      - docker-secrets.env
    environment:
      - SERVICE_NAME=agent-executor
      - SERVICE_PORT=8400
      - VLLM_API_URL=http://vllm-service:8000/v1/chat/completions
      - VLLM_MODEL=/models/Qwen1.5-1.8B-Chat
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8400/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - vllm-service
    volumes:
      - ./scripts:/app/scripts
    networks:
      - agi-internal

  # === AI Self-Cycle Evolution and Optimization Microservices ===
  agi-bayesian-optimizer:
    build:
      context: .
      dockerfile: ./microservices/agi-bayesian-optimizer/Dockerfile
    container_name: agi-bayesian-optimizer
    ports:
      - "8500:8500"
    env_file:
      - .env
    environment:
      - SERVICE_NAME=agi-bayesian-optimizer
      - SERVICE_PORT=8500
      - OPTUNA_STORAGE_URL=sqlite:///data/optuna.db
      - MAX_TRIALS=100
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - agi-redis-lb
    volumes:
      - bayesian-optimizer-data:/app/data
      - ./scripts:/app/scripts
    networks:
      - agi-internal

  agi-adaptive-optimizer:
    build:
      context: .
      dockerfile: ./microservices/agi-adaptive-optimizer/Dockerfile
    container_name: agi-adaptive-optimizer
    ports:
      - "8501:8501"
    env_file:
      - .env
    environment:
      - SERVICE_NAME=agi-adaptive-optimizer
      - SERVICE_PORT=8501
      - HISTORY_SIZE=100
      - ADAPTATION_WINDOW=10
      - MIN_LR=1e-8
      - MAX_LR=1.0
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - agi-redis-lb
    volumes:
      - adaptive-optimizer-data:/app/data
      - ./scripts:/app/scripts
    networks:
      - agi-internal

  agi-optimization-coordinator:
    build:
      context: .
      dockerfile: ./microservices/agi-optimization-coordinator/Dockerfile
    container_name: agi-optimization-coordinator
    ports:
      - "8502:8502"
    env_file:
      - .env
    environment:
      - SERVICE_NAME=agi-optimization-coordinator
      - SERVICE_PORT=8502
      - BAYESIAN_OPTIMIZER_URL=http://agi-bayesian-optimizer:8500
      - ADAPTIVE_OPTIMIZER_URL=http://agi-adaptive-optimizer:8501
      - OPTIMIZATION_TIMEOUT=3600
      - MAX_CONCURRENT_TASKS=10
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8502/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - agi-bayesian-optimizer
      - agi-adaptive-optimizer
      - agi-redis-lb
    volumes:
      - optimization-coordinator-data:/app/data
      - ./scripts:/app/scripts
    networks:
      - agi-internal
      - agi-public

  # === Core Infrastructure Services ===
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    env_file:
      - .env
      - docker-secrets.env
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:5432"
    networks:
      - agi-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  prometheus-data:
  grafana-data:
  redis-data:
  vllm-models:
  bayesian-optimizer-data:
  adaptive-optimizer-data:
  optimization-coordinator-data:

# === Networks Configuration ===
networks:
  agi-public:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
  agi-internal:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.21.0.0/24





# Use the official vLLM image which includes the OpenAI-compatible server
FROM vllm/vllm-openai:latest

# The base image automatically starts the server.
# We don't need to add any extra commands here.
# The model and other configurations will be passed via 'command' in docker-compose.yml.
